#+TITLE: Cloud-Native Movie Review Platform
#+AUTHOR: Twilight4

* Table of Contents :toc:
- [[#project-overview][Project Overview]]
  - [[#full-project-directory-structure][Full Project Directory Structure]]
  - [[#full-architecture-diagram][Full Architecture Diagram]]
  - [[#project-scope--technologies-used][Project Scope / Technologies Used]]
  - [[#prerequisites][Prerequisites]]
  - [[#infrastructure--deployment-model][Infrastructure & Deployment Model]]
- [[#deploy-cloud-infrastructure-wip][Deploy Cloud Infrastructure (WIP)]]
  - [[#terraform-resources-overview][Terraform resources overview]]
  - [[#1-authenticate-and-set-up-gcp][1. Authenticate and set up GCP]]
  - [[#2-create-terraform-state-backend][2. Create Terraform State Backend]]
  - [[#3-manual-cluster-deployment-cd-managed-in-production][3. Manual cluster deployment (CD-managed in production)]]
  - [[#4-manual-application-of-manifests-cd-managed-in-production][4. Manual application of manifests (CD-managed in production)]]
  - [[#5-verify-deployment][5. Verify deployment]]
  - [[#6-clean-up-infrastructure][6. Clean up infrastructure]]
- [[#roadmap-wip][Roadmap (WIP)]]

* Project Overview
This project outlines every stage of the DevOps lifecycle, the tools and how the pieces connect. Everything fully automated end-to-end.

This project demonstrates a full production-grade DevOps setup using modern tooling:
- [[#Containerization][Containerization: Docker]]
- [[#Container-Orchestration][Container Orchestration: Kubernetes + Helm]]
- [[#Cloud-Infrastructure][Cloud Technologies (GCP): GKE, GCR, SQL DB]]
- [[#Cloud-Infrastructure][Infrastructure provisioning: Terraform]]
- [[#CICD][CI/CD pipeline: Github Actions]]
- [[#GitOps][GitOps: ArgoCD]]
- [[#Monitoring-and-Logging][Monitoring and Logging: Prometheus, Grafana]]

** Full Project Directory Structure
#+begin_src shell
full-devops-cycle-project/
├── app/                → Application source code + Dockerfile
│   ├── api-node/
│   │   ├── tests/
│   │   │   └── movies.test.js
│   │   ├── src/
│   │   │   ├── db/
│   │   │   ├── routes/
│   │   │   ├── app.js
│   │   │   └── server.js
│   │   ├── Taskfile.yaml
│   │   ├── package.json
│   │   ├── package-lock.json
│   │   └── Dockerfile
│   ├── Taskfile.yaml
│   └── README.md
│
├── k8s/                → Deployment manifests for multi-env setup
│   ├── overlays/
│   │   ├── staging/
│   │   │   ├── api-node/
│   │   │   │   ├── patches/
│   │   │   │   └── kustomization.yaml
│   │   │   └── kustomization.yaml
│   │   └── production/
│   │       ├── api-node/
│   │       │   ├── patches/
│   │       │   └── kustomization.yaml
│   │       └── kustomization.yaml
│   ├── helm/
│   │   ├── api-node-helm-chart/
│   │   │   ├── templates/
│   │   │   ├── values.yaml
│   │   │   ├── values-staging.yaml
│   │   │   └── Chart.yaml
│   │   └── Taskfile.yaml
│   ├── deploy-services/
│   │   ├── api-node/
│   │   │   ├── namespaces/
│   │   │   ├── manifests/
│   │   │   ├── hostname-staging.yaml
│   │   │   └── hostname-production.yaml
│   │   └── Taskfile.yaml
│   └── Taskfile.yaml
│
├── k8s-cluster-local/      → Docs for Deploying cluster locally
│   ├── kind-bind-mount-2
│   ├── kind-bind-mount-1
│   ├── Taskfile.yaml
│   ├── README.org
│   └── kind-config.yaml.TEMPLATE
│
├── terraform/          → Infrastructure as Code (GCP)
│  ├── modules/
│  │   └── gke/
│  │       ├── variables.tf
│  │       ├── outputs.tf
│  │       └── main.tf
│  ├── envs/
│  │   ├── staging/
│  │   │   ├── variables.tf
│  │   │   ├── terraform.tfvars
│  │   │   ├── main.tf
│  │   │   ├── providers.tf
│  │   │   ├── versions.tf
│  │   │   ├── resources.tf
│  │   │   └── backend.tf
│  │   └── production/
│  │       ├── variables.tf
│  │       ├── terraform.tfvars
│  │       ├── main.tf
│  │       ├── providers.tf
│  │       ├── versions.tf
│  │       ├── resources.tf
│  │       └── backend.tf
│  ├── delete-backend.sh
│  └── backend.sh
│
├── cicd/            → GitOps - ArgoCD configuration
│   ├── github-actions/
│   │   └── Taskfile.yaml
│   ├── argocd-gitops/
│   │   ├── namespaces/
│   │   │   └── argocd.yaml
│   │   ├── clusters/
│   │   │   ├── staging/
│   │   │   │   └── application.yaml
│   │   │   └── production/
│   │   │       └── application.yaml
│   │   └── Taskfile.yaml
│   └── Taskfile.yaml
│
├── monitoring/         → Node + monitoring configuration
│   ├── grafana-dashboards/
│   └── prometheus/
│
├── .github/            → CI/CD pipelines
│   └── workflows/
│       ├── ci.yaml
│       └── cd.yaml
│
├── Taskfile.yaml
└── README.org
#+end_src

** Full Architecture Diagram
#+begin_src shell
                                    ┌──────────────────────────┐
                                    │        Developers        │
                                    └───────────┬──────────────┘
                                                │ git push
                                                ▼
                                      ┌────────────────────┐
                                      │     GitHub Repo    │
                                      └─────────┬──────────┘
                                                │ triggers
                                                ▼
                                  ┌────────────────────────────────┐
                                  │         CI Pipeline            │
                                  └─────────────┬──────────────────┘
                                                │
                                                ▼
                                       ┌──────────────────┐
                                       │ Build Docker Img │
                                       └──────────────────┘
                                                │
                                                ▼ push
                                      ┌──────────────────────┐
                                      │ GCR (Artifact Reg.)  │
                                      └─────────┬────────────┘
                                                │
                                                ▼
                                ┌─────────────────────────────────┐
                                │  CD Pipeline (Helm / Manifests) │
                                └───────────────┬─────────────────┘
                                                │ deploys
                                                ▼

                      ┌──────────────────────────────────────────────────────┐
                      │                GKE Cluster w/ ArgoCD                 │
                      │                                                      │
                      │   ┌────────────┐    ┌─────────────────────────────┐  │
                      │   │ Deployment │--▶│  Horizontal Pod Autoscaler  │  │
                      │   └────────────┘    └─────────────────────────────┘  │
                      │          │                 │                         │
                      │          ▼                 ▼                         │
                      │   ┌────────────┐      ┌──────────────┐               │
                      │   │   Service  │◀──▶│   Ingress    │               │
                      │   └────────────┘      └──────────────┘               │
                      │          │                                           │
                      │          ▼                                           │
                      │   ┌────────────┐                                     │
                      │   │    Pods    │                                     │
                      │   └────────────┘                                     │
                      │                            ArgoCD watches Git repo   │
                      └─────────────────────────┬────────────────────────────┘
                                                │
                                                │
                                                ▼
                                   ┌───────────────────────────┐
                                   │ Cloud SQL (GCP DB NoSQL)│
                                   └────────────┬──────────────┘
                                                │
                                                │
                                                ▼
                                   ┌──────────────────────────┐
                                   │ Monitoring Stack on GKE  │
                                   │ - Prometheus             │
                                   │ - Grafana                │
                                   └──────────────────────────┘

#+end_src

** Project Scope / Technologies Used
*** Containerization
- Dockerfile
- Image optimization

*** Container Orchestration
- Deployments, Services, Ingress
- ConfigMaps and Secrets
- Horizontal Pod Autoscaler (HPA)
- Namespaces and environment separation
- Network policy
- Liveness/readiness probes
- Kustomize overlays
- Helm chart packaging and templating with namespace/env separation

*** Cloud Infrastructure
Terraform provisions GCP infrastructure:
- GKE cluster
- GCS bucket for tfstate backend
- GCP DB NoSQL Database
- VPC, subnets, and firewall rules
- Artifact Registry (GCR)
- IAM roles and service accounts
- Cloud Storage buckets

*** CI/CD
- Build, test pipelines using GitHub Actions
- Docker image building and pushing to GHCR
- Environment-specific deployments (staging, prod)
- Automated application deployment pipeline

*** GitOps
- Automated Kubernetes deployments with ArgoCD
- Declarative Helm charts
- Git-driven versioning and rollbacks

*** Monitoring and Logging
- Prometheus: metrics
- Grafana: dashboards

*** Security
- Kubernetes network policy rules:
  + Allow traffic only from the Ingress Controller
  + Deny ALL other internal pod traffic
  + Allow outbound internet (API needs GCP DB)
- Kubernetes Secret Management
- Terraform IAM least-privilege model

** Prerequisites
- git
- go-task
- docker
- kubectl
- argocd
- kubectx
- minikube or kind
- helm (v3)
- terraform
- GCP subscription
- google-cloud-cli
- google-cloud-cli-gsutil
- google-cloud-cli-component-gke-gcloud-auth-plugin

** Infrastructure & Deployment Model
Important note for users testing this configuration:
- All GKE clusters and Kubernetes manifests are *fully managed by the CD pipeline*
- Manual deployment is *NOT required* for normal operation ([[#3-manual-cluster-deployment-cd-managed-in-production][Step 3]] and [[#4-manual-application-of-manifests-cd-managed-in-production][Step 4]])
- The instructions below exist for:
  - local development / learning
  - debugging
  - reproducing CI/CD behavior manually

The CD pipeline is the *source of truth*. Manual steps should be treated as *optional*.

* Deploy Cloud Infrastructure (WIP)
** Terraform resources overview
Terraform will create resources in the following sequence:
1. VPC network
2. VPC subnet
3. firewall rules
4. GKE cluster
5. ...

** 1. Authenticate and set up GCP
#+begin_src shell
# Change values in root Taskfile.yaml for CLUSTER_NAME, GCP_REGION, GCP_ZONE

# Authenticate to Google Cloud
gcloud auth application-default login

# Create a project
gcloud projects create <PROJECT_NAME>
# Change to another project
gcloud config set project <PROJECT_ID>
# List projects
gcloud projects list

# Set up billing account for your project
## List billing accounts
gcloud billing accounts list
## Check if billing is enabled for a projec
gcloud billing projects describe <PROJECT_ID>
## Link a billing account to a project
gcloud billing projects link <PROJECT_ID> --billing-account=<ACCOUNT_ID>

# Manually enable critical APIs which can not be enabled by Terraform unless they are already enabled
go-task gcp:02-enable-apis 

# Set the default region and zone
gcloud config set compute/region <GCP_REGION>
gcloud config set compute/zone <GCP_ZONE>

# Verify configuration
gcloud config configurations list
#+end_src

** 2. Create Terraform State Backend
Terraform needs a remote backend to store its state.

The =backend.sh= script creates the following resources for currently set project:
- GCS bucket with enabled bucket versioning
- dedicated service account with the privileges: storage.admin and viewer
- key for the Terraform backend

The SA and key are created for the purpose of:
- CI/CD automation (Stable, non-expiring credentials)
- Least privilege access
- Auditability
- Stable & central
- Avoid using user credentials in automation (Actions are logged under the SA, not a human user)

#+begin_src shell
# Modify the LOCATION variable and PROJECT_ID to yours and optionally other vars before executing
./backend.sh

# Store the exported terraform-sa-key.json in a secure place in your local machine e.g. ~/.gcp/terraform-sa-key.json
# The set the GOOGLE_APPLICATION_CREDENTIALS environment variable to point to it (for persistence save in shell profile e.g. .zshrc)
export GOOGLE_APPLICATION_CREDENTIALS="$HOME/.gcp/terraform-sa-key.json"

# If you want to clean up the created resources by backend.sh
PROJECT_ID=<my-project> BUCKET_NAME=<tfstate-12345> ./delete-backend.sh

# To view the created resources
gcloud config get-value project                             # Outputs the current project ID set in gcloud
gcloud storage buckets list --project <PROJECT_ID>          # Check if the bucket exists
gcloud iam service-accounts list --project <PROJECT_ID>     # List all service accounts in the project

# Check the bound iam policies for the created service account
gcloud projects get-iam-policy <PROJECT_ID> \
    --flatten="bindings[].members" \
    --format="table(bindings.role, bindings.members)" \
    --filter="bindings.members:<SA_NAME>@<PROJECT_ID>.iam.gserviceaccount.com"

# NOTE: You don't need to authenticate gcloud using that key
# Terraform will automatically pick up the exported 'GOOGLE_APPLICATION_CREDENTIALS' value
# and execute actions (init, plan, apply) as the SA account
# Authenticate if you want to run gcloud commands as the SA for (debugging or verifying permissions)
gcloud auth activate-service-account --key-file=<KEY_FILE>
# Check which account is active (The * indicates the active account)
gcloud auth list
#+end_src

Then update backend.tf's =bucket= argument to point to the =<BUCKET_NAME>=.

** 3. Manual cluster deployment (CD-managed in production)
WARNING:
If the GKE cluster is deleted manually via the GCP Console or =gcloud=, Terraform state will drift. If you manually delete the cluster, run:
- =terraform state rm google_container_cluster.<name>=

*** Local Systems
**** Minikube
#+begin_src shell
# Start cluster and enable ingress add-on
minikube start
minikube addons enable ingress

# Stop the cluster
minikube stop
#+end_src

**** KinD
The =kind-config.yaml.TEMPLATE= is a template for generating =kind-config.yaml= with =go-task kind:01-generate-config= command which uses 2 extra mounts that the kind cluster is going to mount in to each node for persisting data.

#+begin_src shell
# View task commands
cd k8s-cluster-local
go-task --list-all

# Start cluster with 2 worker nodes
go-task 01-generate-config        # it is going to create one container for control-plane and two containers for worker-nodes
go-task 02-create-cluster

# Verify
kubectl get nodes

# The cloud-provider-kind tool enables to run load-balancers within the kind cluster so we'll be able to access it from the host
# when we'll deploy a service with kind: LoadBalancer, install it when you want to deploy LoadBalancer services
#go-task 03-run-cloud-provider-kind  

# Delete the cluster
go-task 04-delete-cluster
#+end_src

**** Test health endpoint
#+begin_src shell
# Port-forward the service
kubectl port-forward svc/<SVC_NAME> 3000:80 

# OR check from inside of the container
kubectl exec -it <POD_NAME> -- netstat -tlnp           # to sanity-check which port the service is running on
kubectl exec -it <POD_NAME> -- wget -qO- http://localhost:3000/health

xh localhost:3000/health
# Expected output: {"status":"ok"}
#+end_src

*** Deploy on GKE using Terraform
#+begin_src shell
# Select environment to use
cd terraform/envs
# Change the values for terraform.tfvars to match your project_id, region, and zone

# Initialize terraform for production env
go-task 01-init-production

# Validate and review the planned configuration
go-task 02-validate-production
go-task 03-plan-production

# Apply the terraform configuration
go-task 04-apply-production

# Connect to the cluster
go-task gcp:08-connect-to-cluster
# Select cluster to use with kubectl commands
kubectx
#+end_src

*** Deploy on GKE using =google-cloud-cli=
#+begin_src shell
# View task commands from root directory
go-task --list-all

# Create the GCP network, subnet, firewall rules, and cluster in sequence and connect to the GKE cluster
go-task gcp:01-init-cli          # to run gcloud init for automated setup
go-task gcp:07-create-all
go-task gcp:08-connect-to-cluster

# NOTE: If you have deployed additional resources (such as load balancers) that reference the VPC/Subnets/Etc... 
# you may need to manually clean up those resources in order for 'go-task gcp:09-clean-up' command to succeed. 
# You should also verify that you have cleaned up all resources to avoid unwanted costs.

# Connect to the cluster
go-task gcp:08-connect-to-cluster
# Select cluster to use with kubectl commands
kubectx
#+end_src

** 4. Manual application of manifests (CD-managed in production)
NOTE:
In production, manifests are applied automatically via GitOps (ArgoCD).
The following methods are provided for local testing and manual validation only.

*** Using kubectl
#+begin_src shell
# Navigate to Taskfile.yaml directory
cd k8s/deploy-services
go-task --list-all

# Render production env
go-task render-production

# Apply production env
go-task deploy-production

# To delete production env
go-task delete-production
#+end_src

*** Using helm
#+begin_src shell
# Navigate to Taskfile.yaml directory
cd k8s/helm
go-task --list-all

# Render production env
go-task render-template-production

# Install production env
go-task install-template-production

# List realeases
go-task list

# Uninstall production env
go-task uninstall-template-production
#+end_src

*** Using GitOps Setup (ArgoCD)
If you're deploying ArgoCD with minikube/kind, change the server in =application.yaml= to =https://kubernetes.default.svc=.

#+begin_src shell
# Navigate to gitops directory
cd cicd/

# View task commands from root directory
go-task --list-all

# Access argocd UI via port-forwarding the argocd-server
go-task port-forward-webui

# The login is 'admin', to retrieve the password then login to the web UI
go-task get-webui-password

# Deploy staging cluster
go-task deploy-staging-cluster 

# Delete staging cluster
go-task delete-staging-cluster
#+end_src

** 5. Verify deployment
*** Using [[https://console.cloud.google.com/][GCP Portal]]
**** Kubernetes Engine
Clusters/Node Pools:
- Navigate to Kubernetes Engine → Clusters
- Click on a specific cluster → Node pools tab

**** Compute Engine
VM Instances/Disks/Networks & Subnets/Firewall Rules:
- Navigate to Compute Engine → VM instances → Overview
- Navigate to Compute Engine → Disks
- Navigate to VPC network → VPC networks
- Navigate to VPC network → Subnetworks
- Navigate to VPC network → Firewall

**** Cloud Storage
Buckets:
- Navigate to Storage → Browser
- Shows all buckets in the project
- Click a bucket → Objects tab shows stored objects

**** VPC Networks
IP Addresses/Routes/Firewall Rules:
- Navigate to VPC network → External IP addresses
- Navigate to VPC network → Routes
- Navigate to VPC network → Firewall

**** IAM & Service Accounts
Service Accounts/IAM Policies/Roles:
- Navigate to IAM & Admin → Service Accounts
- Navigate to IAM & Admin → IAM

**** APIs & Services
Enabled APIs:
- Navigate to APIs & Services → Dashboard

*** Using =google-cloud-cli=
**** Kubernetes Engine: Clusters / Node Pools
#+begin_src shell
# Check if the cluster is running
gcloud container clusters list --region <REGION>

# Get info about the cluster
gcloud container clusters describe <CLUSTER_NAME> --region <REGION>

# List node pools in a cluster
gcloud container node-pools list --cluster <CLUSTER_NAME> --region <REGION>

# Get info about a specific node pool
gcloud container node-pools describe <NODE_POOL_NAME> --cluster <CLUSTER_NAME> --region <REGION>
#+end_src

**** Compute Engine → Instances / Disks / Networks
#+begin_src shell
# List VM instances
gcloud compute instances list
# or filter by zone
gcloud compute instances list --zones <ZONE>

# List disks
gcloud compute disks list
#+end_src

**** Cloud Storage → Buckets
#+begin_src shell
# List all buckets in a project
gcloud storage buckets list
# or for older versions
gcloud alpha storage buckets list

# Get details of a bucket
gcloud storage buckets describe gs://<BUCKET_NAME>
#+end_src

**** VPC Networks → IP addresses / Firewall
#+begin_src shell
# List networks
gcloud compute networks list

# List subnets
gcloud compute networks subnets list --region <REGION>

# List external IP addresses
gcloud compute addresses list

# List firewall rules (all networks)
gcloud compute firewall-rules list

# List routes
gcloud compute routes list
#+end_src

**** Service Accounts
#+begin_src shell
# List service accounts
gcloud iam service-accounts list

# Get details about a specific service account
gcloud iam service-accounts describe <SA_EMAIL>

# List the IAM roles granted to a service account
gcloud projects get-iam-policy <PROJECT_ID> \
    --flatten="bindings[].members" \
    --format="table(bindings.role, bindings.members)" \
    --filter="bindings.members:<SA_NAME>@<PROJECT_ID>.iam.gserviceaccount.com"
#+end_src

*** Verify GKE api-node service
#+begin_src shell
# GET /movies - Returns list of movies
xh http://<CLUSTER_IP>/movies

# POST /movies - Adds a movie
xh post http://<CLUSTER_IP>/movies title="Avatar 2" rating:=4
xh http://<CLUSTER_IP>/movies

# GET /health - For Kubernetes probes
xh get http://<CLUSTER_IP>/health
# Expected output: {"status":"ok"}
#+end_src

** 6. Clean up infrastructure
#+begin_src shell
# Remove all terraform resources and avoid charges
go-task 05-destroy-production
go-task 07-clean-plan-production

# If you created cluster manually using gcloud, to destroy the cluster run
go-task gcp:09-clean-up
#+end_src


* Roadmap (WIP)
Docker application:
- [X] Write demo movie-review app in NodeJS using Express API
- [X] Implement app logic
- [X] Implement API Endpoints (/health, /movies for POST/GET requests)
- [X] Package app with Dockerfile
- [X] Implement image optimization best practices
- [ ] Add GCP DB integration (env vars, CRUD, routes)

CI/CD:
- [X] Generating image tag
- [X] Building and pushing image to GHCR for multi-architecture
- [X] Update staging/production tags for push to main or release tag
- [X] Create Pull Request with image tag changes
- [ ] Create the infrastructure using terraform
- [ ] Apply the updated manifests into cluster

Kubernetes:
- [X] Create necessary manifest files (deployment, service, ingress)
- [X] Implement Horizontal Pod Autoscaler for movie-api deployment
- [X] Namespaces and environment separation (Dev → debug mode, Staging → test mode)
  + =namePrefix: dev-= for dev overlay
  + namespace overrides
  + patchesStrategicMerge
  + image overrides
- [X] Implement Kustomize overlays
- [ ] Implement GCP DB integration (ConfigMap, Secret, ExternalName Service)
- [ ] Implement network policy for GCP DB database
- [ ] Implement PersistentVolumeClaims to GCP DB
- [X] Implement helm charts packaging and templating with namespace/env separation
- [ ] After GCP DB creation Success:
  + correct the 3 manifests (GCP -service.yaml, secret.yaml, netpo.yaml) and test
  + add the 3 manifests (GCP -service.yaml, secret.yaml, netpo.yaml) to helm chart
  + implement GCP DB integration to node app
- [X] Automated Kubernetes deployments with ArgoCD
- [X] Git-driven versioning and rollbacks 

Terraform - replicate in GCP
- [X] backend config
- [X] IAM roles and service accounts
- [X] VPC
  + [X] Subnet
- [X] GKE cluster
- [X] EC2 instances
- [X] Cloud Storage bucket
- [X] Security groups + rules
- [X] Application load balancer
- [ ] GCP DB database

Grafana, Prometheus:
- [ ] 
